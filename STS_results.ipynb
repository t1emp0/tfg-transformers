{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "pd.options.display.float_format = \"{:.3f}\".format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.read_pickle(\"samples/df_sentences.pkl\")\n",
    "pairs = pd.read_pickle(\"samples/pairs_sentences.pkl\")\n",
    "pairs_QA = pd.read_pickle(\"samples/pairs_sentences_QA.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[200, 114, 314, 324, 124]</td>\n",
       "      <td>[0.96460503, 0.7580036, 0.74133974, 0.73496366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[201, 389, 347, 165, 230]</td>\n",
       "      <td>[0.87307894, 0.84328634, 0.8360214, 0.8266194,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[202, 363, 271, 118, 163]</td>\n",
       "      <td>[0.98577964, 0.8576993, 0.8569913, 0.85006714,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[203, 240, 121, 40, 321]</td>\n",
       "      <td>[0.9916861, 0.8930633, 0.869796, 0.8686416, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[204, 99, 184, 94, 312]</td>\n",
       "      <td>[0.90511703, 0.83434254, 0.82449657, 0.8137258...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                          1  \\\n",
       "0  0  [200, 114, 314, 324, 124]   \n",
       "1  1  [201, 389, 347, 165, 230]   \n",
       "2  2  [202, 363, 271, 118, 163]   \n",
       "3  3   [203, 240, 121, 40, 321]   \n",
       "4  4    [204, 99, 184, 94, 312]   \n",
       "\n",
       "                                                   2  \n",
       "0  [0.96460503, 0.7580036, 0.74133974, 0.73496366...  \n",
       "1  [0.87307894, 0.84328634, 0.8360214, 0.8266194,...  \n",
       "2  [0.98577964, 0.8576993, 0.8569913, 0.85006714,...  \n",
       "3  [0.9916861, 0.8930633, 0.869796, 0.8686416, 0....  \n",
       "4  [0.90511703, 0.83434254, 0.82449657, 0.8137258...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_info(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.drop(columns=0).rename(columns={1: \"top5\", 2: \"score\"})\n",
    "    gt = 2 * sentences.iloc[:][\"avg\"].tolist()\n",
    "    df = pd.concat([df, pd.Series(gt)], axis=1).rename(columns={0: \"gt\"})\n",
    "\n",
    "    df[\"top5\"] = df[\"top5\"].apply(np.array)\n",
    "    df[\"norm\"] = np.abs(np.array(df[\"top5\"]) - df.index) - sentences.shape[0]\n",
    "    df[\"hit@1\"] = df[\"norm\"].apply(lambda x: x[0] == 0)\n",
    "    df[\"hit@5\"] = df[\"norm\"].apply(lambda x: 0 in x)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top5</th>\n",
       "      <th>score</th>\n",
       "      <th>gt</th>\n",
       "      <th>norm</th>\n",
       "      <th>hit@1</th>\n",
       "      <th>hit@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[200, 114, 314, 324, 124]</td>\n",
       "      <td>[0.96460503, 0.7580036, 0.74133974, 0.73496366...</td>\n",
       "      <td>3.000</td>\n",
       "      <td>[0, -86, 114, 124, -76]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[201, 389, 347, 165, 230]</td>\n",
       "      <td>[0.87307894, 0.84328634, 0.8360214, 0.8266194,...</td>\n",
       "      <td>2.000</td>\n",
       "      <td>[0, 188, 146, -36, 29]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[202, 363, 271, 118, 163]</td>\n",
       "      <td>[0.98577964, 0.8576993, 0.8569913, 0.85006714,...</td>\n",
       "      <td>4.000</td>\n",
       "      <td>[0, 161, 69, -84, -39]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[203, 240, 121, 40, 321]</td>\n",
       "      <td>[0.9916861, 0.8930633, 0.869796, 0.8686416, 0....</td>\n",
       "      <td>5.000</td>\n",
       "      <td>[0, 37, -82, -163, 118]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[204, 99, 184, 94, 312]</td>\n",
       "      <td>[0.90511703, 0.83434254, 0.82449657, 0.8137258...</td>\n",
       "      <td>3.000</td>\n",
       "      <td>[0, -105, -20, -110, 108]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        top5  \\\n",
       "0  [200, 114, 314, 324, 124]   \n",
       "1  [201, 389, 347, 165, 230]   \n",
       "2  [202, 363, 271, 118, 163]   \n",
       "3   [203, 240, 121, 40, 321]   \n",
       "4    [204, 99, 184, 94, 312]   \n",
       "\n",
       "                                               score    gt  \\\n",
       "0  [0.96460503, 0.7580036, 0.74133974, 0.73496366... 3.000   \n",
       "1  [0.87307894, 0.84328634, 0.8360214, 0.8266194,... 2.000   \n",
       "2  [0.98577964, 0.8576993, 0.8569913, 0.85006714,... 4.000   \n",
       "3  [0.9916861, 0.8930633, 0.869796, 0.8686416, 0.... 5.000   \n",
       "4  [0.90511703, 0.83434254, 0.82449657, 0.8137258... 3.000   \n",
       "\n",
       "                        norm  hit@1  hit@5  \n",
       "0    [0, -86, 114, 124, -76]   True   True  \n",
       "1     [0, 188, 146, -36, 29]   True   True  \n",
       "2     [0, 161, 69, -84, -39]   True   True  \n",
       "3    [0, 37, -82, -163, 118]   True   True  \n",
       "4  [0, -105, -20, -110, 108]   True   True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = add_info(pairs).head()\n",
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(df: pd.DataFrame) -> Dict:\n",
    "    averages = {\n",
    "        \"max_score\": df[\"score\"].str.get(0).mean(),\n",
    "        \"other_scores\": np.mean(df[\"score\"].str.slice(1, 5).tolist()),\n",
    "        \"hit@1\": df[\"hit@1\"].mean(),\n",
    "        \"hit@5\": df[\"hit@5\"].mean(),\n",
    "        \"miss@1_sum\": df.shape[0] - df[\"hit@1\"].sum(),\n",
    "        \"miss@5_sum\": df.shape[0] - df[\"hit@5\"].sum(),\n",
    "        \"hit@1_gt\": df[df[\"hit@1\"]][\"gt\"].mean(),\n",
    "        \"hit@5_gt\": df[df[\"hit@5\"]][\"gt\"].mean(),\n",
    "        \"miss@1_gt\": df[~df[\"hit@1\"]][\"gt\"].mean(),\n",
    "        \"miss@5_gt\": df[~df[\"hit@5\"]][\"gt\"].mean(),\n",
    "    }\n",
    "    averages[\"scores_diff\"] = averages[\"max_score\"] - averages[\"other_scores\"]\n",
    "    return averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_score': 0.9440532922744751,\n",
       " 'other_scores': 0.8222481,\n",
       " 'hit@1': 1.0,\n",
       " 'hit@5': 1.0,\n",
       " 'miss@1_sum': 0,\n",
       " 'miss@5_sum': 0,\n",
       " 'hit@1_gt': 3.4,\n",
       " 'hit@5_gt': 3.4,\n",
       " 'miss@1_gt': nan,\n",
       " 'miss@5_gt': nan,\n",
       " 'scores_diff': 0.12180519104003906}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "\n",
    "for (model_name, df_aux) in ((\"BERTa\", pairs), (\"multi-qa\", pairs_QA)):\n",
    "    df_aux = add_info(df_aux)\n",
    "    metrics = get_metrics(df_aux)\n",
    "\n",
    "    final_df = pd.concat([final_df, pd.DataFrame(metrics, index=[model_name])])\n",
    "\n",
    "cols = final_df.columns[:-1].insert(2, \"scores_diff\")\n",
    "final_df = final_df[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_score</th>\n",
       "      <th>other_scores</th>\n",
       "      <th>scores_diff</th>\n",
       "      <th>hit@1</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>miss@1_sum</th>\n",
       "      <th>miss@5_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BERTa</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.988</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi-qa</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.943</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          max_score  other_scores  scores_diff  hit@1  hit@5  miss@1_sum  \\\n",
       "BERTa         0.912         0.800        0.112  0.948  0.988          21   \n",
       "multi-qa      0.742         0.553        0.189  0.870  0.943          52   \n",
       "\n",
       "          miss@5_sum  \n",
       "BERTa              5  \n",
       "multi-qa          23  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.iloc[:, :7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hit@1_gt</th>\n",
       "      <th>hit@5_gt</th>\n",
       "      <th>miss@1_gt</th>\n",
       "      <th>miss@5_gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BERTa</th>\n",
       "      <td>2.677</td>\n",
       "      <td>2.653</td>\n",
       "      <td>2.044</td>\n",
       "      <td>1.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi-qa</th>\n",
       "      <td>2.722</td>\n",
       "      <td>2.666</td>\n",
       "      <td>2.122</td>\n",
       "      <td>2.279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          hit@1_gt  hit@5_gt  miss@1_gt  miss@5_gt\n",
       "BERTa        2.677     2.653      2.044      1.884\n",
       "multi-qa     2.722     2.666      2.122      2.279"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.iloc[:, 7:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0973ce1be728d4dc323b4ea761d4cc50400ec6babd1f33dbf3435fda5c4f6b44"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
