{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/PlanTL-GOB-ES/roberta-base-ca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import pickle\n",
    "from typing import List\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65746\n"
     ]
    }
   ],
   "source": [
    "file_path = \"frases.pkl\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    sentences = pickle.load(f)\n",
    "\n",
    "print(len(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and pipeline from huggingface\n",
    "\n",
    "model_name = \"PlanTL-GOB-ES/roberta-base-ca\"\n",
    "\n",
    "tokenizer: AutoTokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "unmasker = pipeline(\"fill-mask\", model=model_name, tokenizer=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es tractava d’una supernova, l’explosió d’una estrella massiva els darrers instants de la seva vida.\n",
      "\n",
      "[0, 546, 10903, 260, 720, 251, 590, 1986, 15022, 15, 265, 720, 251, 21171, 260, 720, 251, 590, 11353, 13736, 338, 3242, 22173, 263, 280, 497, 1096, 17, 2]\n",
      "\n",
      "<s> Es tractava d’una supernova, l’explosió d’una estrella massiva els darrers instants de la seva vida.</s>\n"
     ]
    }
   ],
   "source": [
    "# A simple exploration on what the main functions do\n",
    "\n",
    "random.seed(42)\n",
    "[text] = random.sample(sentences, 1)\n",
    "\n",
    "print(text)\n",
    "print()\n",
    "\n",
    "encoded = tokenizer.encode(text)\n",
    "print(encoded)\n",
    "print()\n",
    "\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MASK_ID = tokenizer.convert_tokens_to_ids(\"<mask>\")\n",
    "MASK_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction helper functions\n",
    "def get_masked_list(ids):\n",
    "    tokenized_list = [ids[:i] + [MASK_ID] + ids[i + 1 :] for i in range(len(ids))]\n",
    "    masked_list = [tokenizer.decode(i) for i in tokenized_list]\n",
    "    return masked_list\n",
    "\n",
    "\n",
    "def predict_masked(masked_sentence):\n",
    "    unmasked = unmasker(masked_sentence)\n",
    "\n",
    "    unmasked_words = [pred[\"token_str\"].strip() for pred in unmasked]\n",
    "    unmasked_scores = [pred[\"score\"] for pred in unmasked]\n",
    "    # [{\"words\": [pred1, pred2], \"scores\": [score1, score2]}, ...]\n",
    "    return {\"words\": unmasked_words, \"scores\": unmasked_scores}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics helper functions\n",
    "def ndcg(item, pred_items: list) -> int:\n",
    "    if item in pred_items:\n",
    "        index = pred_items.index(item)\n",
    "        return np.reciprocal(np.log2(index + 2))\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_hits_dict(original: List[str], predictions: List[List[str]]) -> dict:\n",
    "    TOPS = [1, 3, 5]\n",
    "    tops_dict = {}\n",
    "    for top in TOPS:\n",
    "        top_result = [\n",
    "            word in preds[:top] for (word, preds) in zip(original, predictions)\n",
    "        ]\n",
    "        tops_dict[top] = np.asarray(top_result).mean()\n",
    "    return tops_dict\n",
    "\n",
    "\n",
    "def get_metrics(ids, predictions):\n",
    "    confidence = np.array([pred[\"scores\"][0] for pred in predictions]).mean()\n",
    "\n",
    "    decoded = [tokenizer.decode(i).strip() for i in ids]\n",
    "    pred_words = [pred[\"words\"] for pred in predictions]\n",
    "\n",
    "    ndcg_score = np.array(list(map(ndcg, decoded, pred_words))).mean()\n",
    "    hits_dict = get_hits_dict(decoded, pred_words)\n",
    "\n",
    "    return {\n",
    "        \"conf\": confidence,\n",
    "        \"ndcg_score\": ndcg_score,\n",
    "        \"hits\": hits_dict,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_prediction(text: str):\n",
    "    ids = tokenizer.encode(text)\n",
    "    masked_list = get_masked_list(ids)\n",
    "    predictions = [predict_masked(masked) for masked in masked_list]\n",
    "\n",
    "    metrics = get_metrics(ids, predictions)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data\n",
      "{\n",
      "    \"conf\": 0.641585918336079,\n",
      "    \"ndcg_score\": 0.596054431773405,\n",
      "    \"hits\": {\n",
      "        \"1\": 0.3793103448275862,\n",
      "        \"3\": 0.7586206896551724,\n",
      "        \"5\": 0.7586206896551724\n",
      "    }\n",
      "}\n",
      "\n",
      "Preprocessed data\n",
      "{\n",
      "    \"conf\": 0.7795122174116281,\n",
      "    \"ndcg_score\": 0.7074149715659375,\n",
      "    \"hits\": {\n",
      "        \"1\": 0.5769230769230769,\n",
      "        \"3\": 0.8076923076923077,\n",
      "        \"5\": 0.8076923076923077\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Difference between raw and processed data\n",
    "\n",
    "raw_sentence = \"Es tractava d’una supernova, l’explosió d’una estrella massiva els darrers instants de la seva vida.\"\n",
    "processed_sentence = \"Es tractava d'una supernova, l'explosió d'una estrella massiva els darrers instants de la seva vida.\"\n",
    "\n",
    "raw_result = sentence_prediction(raw_sentence)\n",
    "print(\"Raw data\")\n",
    "print(json.dumps(raw_result, indent=4))\n",
    "print()\n",
    "\n",
    "print(\"Preprocessed data\")\n",
    "processed_result = sentence_prediction(processed_sentence)\n",
    "print(json.dumps(processed_result, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentences[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = SentenceDataset([s[2] for s in sentences])\n",
    "\n",
    "print(len(sents))\n",
    "sents[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b405fe85a251447f97ef20fdabea8af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_SAMPLES = 10000\n",
    "# random.seed(42)\n",
    "# sents = random.sample(sentences, len(results) + NUM_SAMPLES)\n",
    "\n",
    "print(len(results))\n",
    "\n",
    "for i in tqdm(range(NUM_SAMPLES)):\n",
    "    index = len(results)\n",
    "    results.append((index, sentence_prediction(sents[index])))\n",
    "    if (i % 1000) == 0:\n",
    "        with open(\"results_checkpoint.pkl\", \"wb\") as f:\n",
    "            print(i)\n",
    "            pickle.dump(results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_path = \"samples/3_results_10k.pkl\"\n",
    "# results_path = \"samples/4_2_results_10k.pkl\"\n",
    "results_path = \"samples/4_4_results_10-20k.pkl\"\n",
    "with open(results_path, \"rb\") as f:\n",
    "    results = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "ndcg_score: 0.6663205763763352\n",
      "conf:       0.6762789860632521\n",
      "\n",
      "hit1:       0.5704864394340048\n",
      "hit3:       0.7004400136505109\n",
      "hit5:       0.7477276735828828\n"
     ]
    }
   ],
   "source": [
    "print(len(results))\n",
    "\n",
    "data = [r[1] for r in results]\n",
    "\n",
    "averages = {\n",
    "    \"ndcg_score\": np.array([r[\"ndcg_score\"] for r in data]).mean(),\n",
    "    \"conf\": np.array([r[\"conf\"] for r in data]).mean(),\n",
    "    \"hit1\": np.array([r[\"hits\"][1] for r in data]).mean(),\n",
    "    \"hit3\": np.array([r[\"hits\"][3] for r in data]).mean(),\n",
    "    \"hit5\": np.array([r[\"hits\"][5] for r in data]).mean(),\n",
    "}\n",
    "\n",
    "# Printing the results\n",
    "just_len = max([len(key) for key in averages.keys()]) + 1\n",
    "\n",
    "for (k, v) in averages.items():\n",
    "    print(f\"{k}:\".ljust(just_len, \" \"), v)\n",
    "    if k == \"conf\":\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0973ce1be728d4dc323b4ea761d4cc50400ec6babd1f33dbf3435fda5c4f6b44"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
